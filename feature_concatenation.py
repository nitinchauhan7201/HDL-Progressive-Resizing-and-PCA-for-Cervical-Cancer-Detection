# -*- coding: utf-8 -*-
"""feature_concatenation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HY_nKHHWSW0jqCFPCg0qK73OpDKfauwI
"""

### MODELS
import numpy as np
from pathlib import Path
import sys
from keras.layers import Dense, GlobalMaxPool2D, BatchNormalization, Dropout
from keras.applications import VGG16, ResNet152
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model, Sequential
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras import layers
import matplotlib.pyplot as plt

"""LOAD DATA"""
# path to folder with data
import os
os.getcwd()
os.chdir(r"C:\Users\nitin\Desktop\Cervical_Cancer_Detection")
path = "\SIPaKMeD_224x224"

# expected data structure inside folder: train, test, val. in each folder: one folder for each class,
train_datagen = ImageDataGenerator(featurewise_center=False,
                                   rotation_range = 20, fill_mode="nearest",
                                   zoom_range=[1/1.2, 1/1.2], width_shift_range=0.2, height_shift_range=0.2,
                                   horizontal_flip = True, vertical_flip=True,
                                   brightness_range=[0.4, 1.4], channel_shift_range=20)

DA_IDG = ImageDataGenerator()

# in training set: use data augmentation image data generator, for validation and test: no data augmentation.
training_set_224 = train_datagen.flow_from_directory(path+"train\",
                                                target_size=(224, 224), # typical imagenet dimensions
                                                color_mode='rgb',
                                                batch_size=64,
                                                class_mode='categorical', shuffle=True)

validation_set_224 = DA_IDG.flow_from_directory(path+"val\",
                                                target_size=(224, 224),
                                                color_mode='rgb',
                                                class_mode='categorical',
                                                shuffle=True)

test_set_224 = DA_IDG.flow_from_directory(path+"test\",
                                                target_size=(224, 224),
                                                color_mode='rgb',
                                                batch_size=1,
                                                class_mode='categorical',
                                                shuffle=False)

###############################################################################################

# path to folder with data
path = "\SIPaKMeD_512x512"

# expected data structure inside folder: train, test, val. in each folder: one folder for each class,
training_set_512 = train_datagen.flow_from_directory(path+"train\",
                                                target_size=(512, 512), # typical imagenet dimensions
                                                color_mode='rgb',
                                                batch_size=64,
                                                class_mode='categorical', shuffle=True)

validation_set_512 = DA_IDG.flow_from_directory(path+"val\",
                                                target_size=(512, 512),
                                                color_mode='rgb',
                                                class_mode='categorical',
                                                shuffle=True)

test_set_512 = DA_IDG.flow_from_directory(path+"test\",
                                                target_size=(512, 512),
                                                color_mode='rgb',
                                                batch_size=1,
                                                class_mode='categorical',
                                                shuffle=False)

###############################################################################################

# path to folder with data
path = "\SIPaKMeD_1024x1024"

# expected data structure inside folder: train, test, val. in each folder: one folder for each class,
training_set_1024 = train_datagen.flow_from_directory(path+"train\",
                                                target_size=(1024, 1024), # typical imagenet dimensions
                                                color_mode='rgb',
                                                batch_size=64,
                                                class_mode='categorical', shuffle=True)

validation_set_1024 = DA_IDG.flow_from_directory(path+"val\",
                                                target_size=(1024, 1024),
                                                color_mode='rgb',
                                                class_mode='categorical',
                                                shuffle=True)

test_set_1024 = DA_IDG.flow_from_directory(path+"test\",
                                                target_size=(1024, 1024),
                                                color_mode='rgb',
                                                batch_size=1,
                                                class_mode='categorical',
                                                shuffle=False)
###############################################################################################

def VGG(seed = None):
    np.random.seed(seed)
    vgg16 = VGG16(weights="imagenet", include_top=False)
    for layer in vgg16.layers[:13]:
        layer.trainable = False
    for layer in vgg16.layers[13:]:
        layer.trainable = True
    y = (vgg16.get_layer("block4_conv3")).output
    mx_y = GlobalMaxPool2D()(y)
    x = BatchNormalization()(mx_y)
    x = Dropout(.5)(x)
    x = Dense(1024, activation='relu', name="dense_1024")(x)
    x = BatchNormalization()(x)
    x = Dropout(.5)(x)
    preds = Dense(5,activation='softmax')(x)
    model = Model(inputs=vgg16.input,outputs=preds)
    return model

def Resnet152(seed = None):
    resNet = ResNet152(weights="imagenet", include_top=False)
    for layer in resNet.layers[:121]:
        layer.trainable = False
    for layer in resNet.layers[121:]:
        layer.trainable = True
    y = (resNet.get_layer("conv4_block1_1_conv")).output
    mx_y = GlobalMaxPool2D()(y)
    x = BatchNormalization()(mx_y)
    x = Dropout(.5)(x)
    x = Dense(1024, activation='relu', name="dense_1024")(x)
    x = BatchNormalization()(x)
    x = Dropout(.5)(x)
    preds = Dense(5,activation='softmax')(x)
    model = Model(inputs=resNet.input,outputs=preds)
    return model

model_vgg = VGG()
model_resnet152 = Resnet152()

#Concatenation of Two models from First Iteration

import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Input, Concatenate, Dense
from tensorflow.keras.models import Model

# Load pre-trained models with custom weights
model1 = load_model('resnet152_iteration1.h5')
model2 = load_model('vgg_iteration1.h5')

# Check if models have the expected output shape
assert model1.output_shape == (None, 1024), "Model 1 output shape should be (None, 1024)"
assert model2.output_shape == (None, 1024), "Model 2 output shape should be (None, 1024)"

# Define input layers for both models
input1 = Input(shape=(1024,))
input2 = Input(shape=(1024,))

# Define models to get features
model1_features = model1(input1)
model2_features = model2(input2)

# Concatenate the features from both models
concatenated_features1 = Concatenate()([model1_features, model2_features])

# Optionally, add a dense layer for further processing
final_output1 = Dense(1, activation='sigmoid')(concatenated_features1)  # Adjust as needed

# Create the concatenated model
concatenated_model1 = Model(inputs=[input1, input2], outputs=final_output1)

# Compile the model (adjust optimizer and loss as necessary)
concatenated_model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Print the summary of the concatenated model
concatenated_model1.summary()

# Save the concatenated model to a new file
concatenated_model1.save('concatenate_model1.h5')

#Concatenation of Two models from Second Iteration

import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Input, Concatenate, Dense
from tensorflow.keras.models import Model

# Load pre-trained models with custom weights
model1 = load_model('resnet152_iteration2.h5')
model2 = load_model('vgg_iteration2.h5')

# Check if models have the expected output shape
assert model1.output_shape == (None, 1024), "Model 1 output shape should be (None, 1024)"
assert model2.output_shape == (None, 1024), "Model 2 output shape should be (None, 1024)"

# Define input layers for both models
input1 = Input(shape=(1024,))
input2 = Input(shape=(1024,))

# Define models to get features
model1_features = model1(input1)
model2_features = model2(input2)

# Concatenate the features from both models
concatenated_features2 = Concatenate()([model1_features, model2_features])

# Optionally, add a dense layer for further processing
final_output2 = Dense(1, activation='sigmoid')(concatenated_features2)  # Adjust as needed

# Create the concatenated model
concatenated_model2 = Model(inputs=[input1, input2], outputs=final_output2)

# Compile the model (adjust optimizer and loss as necessary)
concatenated_model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Print the summary of the concatenated model
concatenated_model2.summary()

# Save the concatenated model to a new file
concatenated_model2.save('concatenate_model2.h5')

#Concatenation of Two models from First Iteration

import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Input, Concatenate, Dense
from tensorflow.keras.models import Model

# Load pre-trained models with custom weights
model1 = load_model('resnet152_iteration1.h5')
model2 = load_model('vgg_iteration1.h5')

# Check if models have the expected output shape
assert model1.output_shape == (None, 1024), "Model 1 output shape should be (None, 1024)"
assert model2.output_shape == (None, 1024), "Model 2 output shape should be (None, 1024)"

# Define input layers for both models
input1 = Input(shape=(1024,))
input2 = Input(shape=(1024,))

# Define models to get features
model1_features = model1(input1)
model2_features = model2(input2)

# Concatenate the features from both models
concatenated_features3 = Concatenate()([model1_features, model2_features])

# Optionally, add a dense layer for further processing
final_output3 = Dense(1, activation='sigmoid')(concatenated_features3)  # Adjust as needed

# Create the concatenated model
concatenated_model3 = Model(inputs=[input1, input2], outputs=final_output3)

# Compile the model (adjust optimizer and loss as necessary)
concatenated_model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Print the summary of the concatenated model
concatenated_model3.summary()

# Save the concatenated model to a new file
concatenated_model3.save('concatenate_model3.h5')